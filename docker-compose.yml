services:

  # =========================
  # ZOOKEEPER
  # =========================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181

  # =========================
  # KAFKA
  # =========================
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181

      KAFKA_LISTENERS: INTERNAL://0.0.0.0:29092,EXTERNAL://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:29092,EXTERNAL://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL

      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  # =========================
  # CASSANDRA
  # =========================
  cassandra:
    image: cassandra:4.1
    container_name: cassandra
    ports:
      - "9042:9042"

  # =========================
  # CASSANDRA INIT
  # =========================
  cassandra-init:
    image: cassandra:4.1
    container_name: cassandra-init
    depends_on:
      - cassandra
    volumes:
      - ./cassandra/init.cql:/init.cql
    entrypoint: >
      bash -c "
      until cqlsh cassandra 9042; do
        echo 'Waiting for Cassandra...';
        sleep 5;
      done &&
      cqlsh cassandra 9042 -f /init.cql
      "

  # =========================
  # PYTHON PRODUCER
  # =========================
  producer:
    build:
      context: .
      dockerfile: producer/Dockerfile
    container_name: producer
    depends_on:
      - kafka
    volumes:
      - ./data/nasa.log:/app/nasa.log
      - ./producer/producer.py:/app/producer.py
    environment:
      KAFKA_BROKER: kafka:29092
    working_dir: /app
    command: python producer.py
    restart: unless-stopped

  # =========================
  # SPARK MASTER
  # =========================
  spark-master:
    image: apache/spark:3.5.0
    container_name: spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    ports:
      - "8080:8080"

  # =========================
  # SPARK WORKER
  # =========================
  spark-worker:
    image: apache/spark:3.5.0
    container_name: spark-worker
    depends_on:
      - spark-master
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077

  # =========================
  # SPARK SUBMIT CLIENT
  # =========================
  spark-submit-client:
    image: apache/spark:3.5.0
    container_name: spark-submit-client
    depends_on:
      - spark-master
      - kafka
      - cassandra
    volumes:
      - ./spark:/app
      - ./ivy-cache:/tmp/ivy
    environment:
      SPARK_LOCAL_DIRS: /tmp
    command: >
      /opt/spark/bin/spark-submit
      --master spark://spark-master:7077
      --conf spark.jars.ivy=/tmp/ivy
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.datastax.spark:spark-cassandra-connector_2.12:3.5.0
      /app/spark_streaming.py
    restart: unless-stopped

  # =========================
  # DASHBOARD
  # =========================
  dashboard:
    image: python:3.10
    container_name: dashboard
    depends_on:
      - cassandra
    volumes:
      - ./dashboard:/app
    working_dir: /app
    command: >
      bash -c "
      pip install streamlit cassandra-driver plotly &&
      streamlit run app.py --server.port=8501 --server.address=0.0.0.0
      "
    ports:
      - "8501:8501"
